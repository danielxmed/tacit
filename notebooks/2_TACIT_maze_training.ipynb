{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m97tx5a8vza3",
        "outputId": "2bbb4ee4-dbc3-40cd-bfa9-ed92b88962d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "Memory: 15.8 GB\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import os\n",
        "import time\n",
        "\n",
        "from safetensors.torch import save_file, load_file\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Mount Drive and set paths\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_DIR = Path('/content/drive/MyDrive/notebooks_tacit/maze_dataset')\n",
        "CHECKPOINT_DIR = Path('/content/drive/MyDrive/notebooks_tacit/checkpoints')\n",
        "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Verify data exists\n",
        "batch_files = sorted(DATA_DIR.glob('batch_*.npz'))\n",
        "print(f\"Found {len(batch_files)} batch files\")\n",
        "print(f\"First: {batch_files[0].name}\")\n",
        "print(f\"Last: {batch_files[-1].name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa8buGFH63bj",
        "outputId": "042e3196-e411-4903-bb2f-a2f85df5c3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 100 batch files\n",
            "First: batch_0000.npz\n",
            "Last: batch_0099.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Dataset class\n",
        "\n",
        "class MazeDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset that loads maze pairs from .npz batch files.\n",
        "\n",
        "    Loads batches lazily to avoid memory issues with 1M samples.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_dir: str, num_batches: int = None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_dir: path to directory containing batch_XXXX.npz files\n",
        "            num_batches: how many batches to use (None = all)\n",
        "        \"\"\"\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.batch_files = sorted(self.data_dir.glob('batch_*.npz'))\n",
        "\n",
        "        if num_batches is not None:\n",
        "            self.batch_files = self.batch_files[:num_batches]\n",
        "\n",
        "        # Load first batch to get batch size\n",
        "        first_batch = np.load(self.batch_files[0])\n",
        "        self.batch_size = len(first_batch['inputs'])\n",
        "        first_batch.close()\n",
        "\n",
        "        self.total_samples = len(self.batch_files) * self.batch_size\n",
        "\n",
        "        # Cache for current loaded batch (avoid reloading constantly)\n",
        "        self._cached_batch_idx = -1\n",
        "        self._cached_inputs = None\n",
        "        self._cached_outputs = None\n",
        "\n",
        "        print(f\"Dataset: {self.total_samples:,} samples from {len(self.batch_files)} batches\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.total_samples\n",
        "\n",
        "    def _load_batch(self, batch_idx: int):\n",
        "        \"\"\"Load a batch into cache.\"\"\"\n",
        "        if batch_idx != self._cached_batch_idx:\n",
        "            batch_data = np.load(self.batch_files[batch_idx])\n",
        "            self._cached_inputs = batch_data['inputs']\n",
        "            self._cached_outputs = batch_data['outputs']\n",
        "            self._cached_batch_idx = batch_idx\n",
        "            batch_data.close()\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        \"\"\"\n",
        "        Returns a single (input, output) pair as tensors.\n",
        "\n",
        "        Images are converted from uint8 [0, 255] to float32 [0, 1]\n",
        "        and from (H, W, C) to (C, H, W) for PyTorch.\n",
        "        \"\"\"\n",
        "        batch_idx = idx // self.batch_size\n",
        "        sample_idx = idx % self.batch_size\n",
        "\n",
        "        self._load_batch(batch_idx)\n",
        "\n",
        "        # Get images as numpy arrays\n",
        "        input_img = self._cached_inputs[sample_idx]\n",
        "        output_img = self._cached_outputs[sample_idx]\n",
        "\n",
        "        # Convert to tensor: uint8 [0,255] -> float32 [0,1]\n",
        "        # Transpose: (H, W, C) -> (C, H, W)\n",
        "        input_tensor = torch.from_numpy(input_img).permute(2, 0, 1).float() / 255.0\n",
        "        output_tensor = torch.from_numpy(output_img).permute(2, 0, 1).float() / 255.0\n",
        "\n",
        "        return input_tensor, output_tensor"
      ],
      "metadata": {
        "id": "lm7LaJC18cjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Test the dataset\n",
        "\n",
        "dataset = MazeDataset(DATA_DIR, num_batches=10)  # Just 10 batches for testing\n",
        "\n",
        "# Get a sample\n",
        "inp, out = dataset[0]\n",
        "print(f\"Input shape: {inp.shape}\")   # Should be (3, 64, 64)\n",
        "print(f\"Output shape: {out.shape}\")  # Should be (3, 64, 64)\n",
        "print(f\"Value range: [{inp.min():.2f}, {inp.max():.2f}]\")  # Should be [0, 1]\n",
        "\n",
        "# Visualize\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
        "for i in range(4):\n",
        "    idx = np.random.randint(len(dataset))\n",
        "    inp, out = dataset[idx]\n",
        "\n",
        "    # Convert back to (H, W, C) for plotting\n",
        "    axes[0, i].imshow(inp.permute(1, 2, 0))\n",
        "    axes[0, i].set_title(f'Input #{idx}')\n",
        "    axes[0, i].axis('off')\n",
        "\n",
        "    axes[1, i].imshow(out.permute(1, 2, 0))\n",
        "    axes[1, i].set_title(f'Output #{idx}')\n",
        "    axes[1, i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "Lg2oJ7CSRjdj",
        "outputId": "d8f852af-907b-4e87-e206-9cdafc5d406c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: 100,000 samples from 10 batches\n",
            "Input shape: torch.Size([3, 64, 64])\n",
            "Output shape: torch.Size([3, 64, 64])\n",
            "Value range: [0.00, 1.00]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 8 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJEAAAJRCAYAAAD1diY8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATHVJREFUeJzt3XmUVMXdP/5Ps6+CLKIiIuCC4IIacYlCohg1LqhB0bjg9rhvUR98TEzcjSv6KHH364pEYzTGxMRoYiLu60/j9mBUNCouoAKCCEL9/vAwcZhhaoaZnu6Zeb3O4XDmdnXdunW7a26/p251IaWUAgAAAABq0KrUDQAAAACg/AmRAAAAAMgSIgEAAACQJUQCAAAAIEuIBAAAAECWEAkAAACALCESAAAAAFlCJAAAAACyhEgAAAAAZAmRAAAAAMgSIjWwm266KQqFQjz77LOlbkpERMybNy/OOOOM+Pvf/75cz//888+jVatW8cADD0RExD333BPt27ePr776qlK5L774Ik4//fTYYYcdokePHlEoFOKmm25aZr0TJ06MddddN9q3bx99+/aNE088MebOnVupzOuvvx7jx4+PYcOGRdeuXWOVVVaJnXbaqdq+vfvuu2Ps2LExcODA6NSpU6yzzjpx0kknxeeff16l7E9+8pPYeOONo0ePHtGpU6dYd91144wzzogvvvii7h0ETUhLHZ9eeeWV2HPPPSvGh169esWIESPivvvuq7bexYsXx1VXXRXDhg2Ljh07Rs+ePWObbbaJF198sVK5c889N3bdddfo06dPFAqFOOOMM2ps7x133BFbbLFFdO7cObp37x5bbrll/O1vf6tS7oYbboh11103OnToEGuttVZcccUVdegVaLqMUbUbo2pzDRXxzVh24YUXxoABA6JDhw6xwQYbxOTJk+tV5/Tp0+Owww6LAQMGRMeOHWPQoEFx4oknxsyZM+vaPdCktNTxaWnnnntuFAqFWG+99ao8tnjx4rj66qtj2LBh0aVLl+jTp0/suOOO8fjjj1cqV5fPjQceeGAUCoUq/wYPHlyp3BlnnFFtuSX/HnvssTr0DjltSt0AimvevHlx5plnRkTE9773vTo//+mnn46IiM022ywiIp544onYaKONon379pXKzZgxI84666xYffXVY8MNN6xxQDvllFPiwgsvjDFjxsTxxx8fr776alxxxRXxyiuvVAxkERHXX3993HDDDfGjH/0ojjrqqJg1a1Zcc801sfnmm8ef//znGDVqVEXZww47LFZdddXYb7/9YvXVV49//vOfMXHixLj//vvj+eefj44dO1aUfeaZZ2LrrbeOgw46KDp06BAvvPBCnH/++fHQQw/FI488Eq1ayVahMTTW+PTOO+/EnDlzYty4cbHqqqvGvHnz4re//W3suuuucc0118Rhhx1WqfzBBx8ckyZNigMOOCCOOeaYmDt3brzwwgvx8ccfVyp32mmnxcorrxwbbbRRpbGrOmeccUacddZZMWbMmDjwwANj4cKF8fLLL8f7779fqdw111wTRxxxRPzoRz+KE088MaZMmRLHHXdczJs3L0455ZQ69xGw/MpxjKrtNVRExM9+9rM4//zz47/+679i0003jXvvvTd+/OMfR6FQiL333rvOdX7xxRexxRZbxNy5c+Ooo46Kfv36xYsvvhgTJ06Mhx9+OJ577jnXUNBIGmt8+rb33nsvzjvvvOjcuXO1j//3f/93TJgwIfbbb7846qij4vPPP49rrrkmRo4cGY899lgMHz48Iur2uTEion379nH99ddX2tatW7dKP++xxx6x5pprVnnuT3/60/jiiy9i0003rXEf1FGiQd14440pItIzzzxT6qaklFL65JNPUkSk008/fbmef/bZZ6fBgwdX/LzVVlul4447rkq5+fPnp+nTp6eUUnrmmWdSRKQbb7yxSrkPPvggtWnTJu2///6Vtl9xxRUpItLvf//7im3PPvtsmjNnTqVyM2bMSL17907f/e53K21/+OGHq+zr5ptvThGRrrvuuuxxXnzxxSki0hNPPJEtC01VSx2fqvP111+nDTfcMK2zzjqVtt9xxx0pItLdd9+drePtt99OKeWP44knnkiFQiFNmDChxvrmzZuXevbsmXbaaadK2/fdd9/UuXPn9Omnn2bbBE2ZMeo/qhuj6nIN9d5776W2bdumo48+umLb4sWL09Zbb51WW2219PXXX9e5zkmTJqWISH/4wx8qlf3FL36RIiI9//zztTo2aIqMTymNHTs2bbPNNmnkyJFp6NChlR5buHBh6tixYxozZkyl7W+99VaKiEp11/ZzY0opjRs3LnXu3Lkuh1bh3XffTYVCIf3Xf/3Xcj2fZfPngkZw4IEHRpcuXeL999+P3XbbLbp06RK9e/eOk08+ORYtWlRRbtq0aVEoFOLiiy+OSy+9NPr37x8dO3aMkSNHxssvv1ypzu9973vVps4HHnhgrLHGGhX19e7dOyIizjzzzIrpfLlbLmbNmhUzZsyIGTNmxBNPPBEbbrhhzJgxIz766KN47rnnYvDgwTFjxoyYNWtWxXPat28fK6+8crYvnnjiifj6668r/QUsIip+/vWvf12xbZNNNokuXbpUKtezZ8/Yeuut47XXXqu0vbq+2H333SMiqpStzpI+q+72N2jOWsL4VJ3WrVtHv379qrznJ0yYEMOHD4/dd989Fi9eXO3tHEssOZacyy67LFZeeeU4/vjjI6W0zFtnH3744Zg5c2YcddRRlbYfffTRMXfu3PjjH/9Yq/1Bc2KM+rxiW12uoe69995YuHBhpfGkUCjEkUceGe+991488cQTda5z9uzZERHRp0+fSmVXWWWViIhKs76hJWhJ49MjjzwSd911V1x22WXV1r1w4cL48ssvq4wPK620UrRq1arS+FDbz43ftmjRoooxqLYmT54cKaXYd9996/Q88oRIjWTRokWx/fbbR8+ePePiiy+OkSNHxiWXXBLXXnttlbK33HJLXH755XH00UfHqaeeGi+//HJss8028dFHH9Vpn717946rrroqIr4JVG699da49dZbY4899qjxeaNHj47evXtH79694/7774877rgjevfuHSuvvHJ8+eWXcdRRR0Xv3r1j9OjRdWpPRFTcZ7v0hUanTp0iIuK5557L1vHhhx9Gr169alUuIqot+/XXX8eMGTPigw8+iL/85S9x2mmnRdeuXSumWUJL0lLGp7lz58aMGTPizTffjEsvvTT+9Kc/xbbbblvx+OzZs+Ppp5+OTTfdNH76059Gt27dokuXLjFw4MC4884763R83/bXv/41Nt1007j88sujd+/eFWu8TZw4sVK5F154ISIivvOd71Tavskmm0SrVq0qHoeWxhj1jbpcQ73wwgvRuXPnWHfddSuVXXKds2Q8qUudI0aMiFatWsXxxx8fTz75ZLz33ntx//33x7nnnhu77bZblTVKoCVoCePTokWL4thjj41DDz001l9//Wrr7tixY2y22WZx0003xaRJk+Ldd9+Nl156KQ488MBYccUVqywdUBfz5s2LFVZYIbp16xY9evSIo48+ulZr2U6aNCn69esXI0aMWO59swylngrV3FQ31XHcuHEpItJZZ51VqexGG22UNtlkk4qf33777RQRqWPHjum9996r2P7UU0+liEg/+clPKraNHDkyjRw5ssr+x40bl/r371/x8/JMdXz22WfTgw8+mH71q1+liEi33XZbevDBB9OBBx6Y+vXrlx588MH04IMPpmeffbba59c0LfG5555LEZHOPvvsStv//Oc/p4hIXbp0qbFtjzzySCoUCunnP/959jgOOeSQ1Lp16zR16tQqjz3xxBMpIir+rbPOOtXeEgfNSUsfnw4//PCK93yrVq3SmDFjKt0i9vzzz6eISD179kx9+vRJV155ZZo0aVIaPnx4KhQK6U9/+lO1barpOD799NOKOrt06ZIuuuiidMcdd6QddtghRUS6+uqrK8oeffTRqXXr1tXuo3fv3mnvvfeudT9BU2SMqnmMqss11E477ZQGDhxYZR9z585NEZH+53/+p851ppTS9ddfn7p3717pGmrcuHFp4cKFte4jaIpa8vg0ceLE1K1bt/Txxx9XtHHp29lSSumNN95IG2+8caXxYeDAgen1119fZptyt7P9z//8TzrllFPSHXfckSZPnlzR59/97ndrHHdefvnlFBFp/PjxtegZ6srC2o3oiCOOqPTz1ltvHbfeemuVcrvttlv07du34ufhw4fHZpttFvfff39MmDCh6O3cZJNNIiLi1VdfjVVXXbViCuBll10W2267baUFretq4403js022ywuuOCC6Nu3b3z/+9+P1157LY488sho27ZtfPnll8t87scffxw//vGPY8CAATF+/Pga93P77bfHDTfcEOPHj4+11lqryuNDhgyJBx98MObOnRuPP/54PPTQQ76djRatJYxPJ5xwQowZMyY++OCDuPPOO2PRokWxYMGCiseXjAEzZ86MJ598smKxyV133TUGDBgQ55xzTuywww51au+36/z1r38dY8eOjYiIMWPGxPrrrx/nnHNOHH744RER8eWXX0a7du2qradDhw41jo/Q3Bmj6nYN9eWXX1a7QG6HDh0qHq9rnRERffv2jeHDh8cPf/jD6N+/f0yZMiUuv/zy6NWrV1x88cXL2WvQtDXn8WnmzJnxi1/8In7+859X3EK3LF27do2hQ4fGFltsEdtuu218+OGHcf7558duu+0WU6ZMqdWdJEv75S9/WennvffeO9Zee+342c9+FnfddVeVW3GXmDRpUkSEW9mKxO1sjaRDhw5V3ngrrrhifPbZZ1XKVhd6rL322jFt2rRiNa/CF198UXGv7IMPPhibb755zJgxIz7++OOYMmVKbLzxxjFjxoxq211bv/3tb2PDDTeMgw8+OAYMGBC77LJL7LXXXrHRRhtVWQNpiblz58bOO+8cc+bMiXvvvXeZ5SIipkyZEoccckhsv/32ce6551ZbZoUVVohRo0bF6NGj44ILLoiTTjopRo8eXeUrvKElaCnj0+DBg2PUqFFxwAEHxB/+8If44osvYpdddomUUkT853aOAQMGVARIERFdunSJXXbZJZ5++un4+uuv69TmJXW2bds2xowZU7G9VatWMXbs2Hjvvffi3XffrSj77Q+M3zZ//nzrjdBiGaNSRZnaXkN17Nix2q/qnj9/fsXjda3zsccei5133jnOPffcOP7442O33XaLSy65JE477bSYMGFCvPrqq/XuQ2hqmvv4dNppp0WPHj3i2GOPrbH+r7/+OkaNGhXdunWLiRMnxu677x5HHnlkPPTQQ/Hmm2/GRRdd1GDH8pOf/CRatWoVDz30ULWPp5Ti9ttvj/XWWy822GCDBtsv/yFEaiStW7du0PoKhUK127+9iNvyOOaYYyrulf3DH/4Qd999d/Tu3Tv69OkTs2fPjuOOOy569+4dG2200XLvo2/fvvHoo4/G1KlT45FHHon33nsvLrzwwvj3v/8da6+9dpXyCxYsiD322CNeeumluPfee2O99dZbZt0vvvhi7LrrrrHeeuvFXXfdFW3a1G6y3ZJ7iL+9gCS0FC11fBozZkw888wzMXXq1IiIWHXVVSOi6qKxEd8sDLlw4cIaF9quTo8ePaJDhw7Rs2fPKv280korRURUXLCtssoqsWjRovj4448rlVuwYEHMnDmzon3Q0hijplZsq+011CqrrBIffvhhpQAqImL69OkREZXGk9rWec0110SfPn2qrNu26667RkopHn/88dp3FjQTzXl8euONN+Laa6+N4447Lj744IOYNm1aTJs2LebPnx8LFy6MadOmxaeffhoR3yy8/fLLL8euu+5aab9rrbVWrLvuuvHYY4/Vq/3f1rFjx+jZs2fFvpf22GOPxTvvvGMWUhG5na0MvfHGG1W2TZ06tdI3Aa244orx1ltvVSn3zjvvVPp5WQPRsowfPz7222+/ePvtt+Owww6LW265JVZZZZW488474/7774+bbropIhrmGzjWWmutikT+1VdfjenTp8eBBx5YqczixYvjgAMOiL/+9a9x5513xsiRI5dZ35tvvhk77LBDrLTSSnH//ffXOFtpaV999VUsXrw4+20p0NI1p/FpyW0aS973q666aqy88srx/vvvVyn7wQcfRIcOHaJr1651anOrVq1i2LBh8cwzz8SCBQsq3a72wQcfRERU/AVz2LBhERHx7LPPxg9/+MOKcs8++2wsXry44nFg2ZrzGPVtuWuoYcOGxfXXXx+vvfZaDBkypGL7U089VfF4Xev86KOPqv0gu3DhwoiIOs/UhJamqY1P77//fixevDiOO+64OO6446rUOWDAgDj++OPjsssuq1gcfFljREOOD3PmzIkZM2Ys8/a6SZMmRaFQiB//+McNtk8qMxOpDP3ud7+r9CHm6aefjqeeeip23HHHim2DBg2K119/PT755JOKbS+++GKVlHfJt2vU9qvrhwwZEqNGjYo2bdrEiiuuGPvtt1+MGjUqZs+eHVtttVWMGjUqRo0aFd/97nfrcYSVLV68OMaPHx+dOnWqck/xscceG3fccUdceeWVNX7jwIcffhg/+MEPolWrVvHAAw8sc1D5/PPPKy52vu3666+PiKrfigRU1hTHp6Vn9kR8c0Fzyy23RMeOHSt9wBo7dmz8+9//jgcffLBi24wZM+Lee++NbbbZJlq1qvuvzbFjx8aiRYvi5ptvrtg2f/78mDRpUgwZMqRiRsA222wTPXr0qPjGlSWuuuqq6NSpU+y000513je0NM19jFrasq6hRo8eHW3bto0rr7yyYltKKa6++uro27dvbLnllnWuc+21146PPvoo/v73v1cqP3ny5IiIes1Sh5agqY1P6623Xtxzzz1V/g0dOjRWX331uOeee+KQQw6JiKiYtbj0XR3PP/98/N///d9yjQ/z58+POXPmVNl+9tlnR0qp2nUqFy5cGL/5zW9iq622itVXX73O+6R2zEQqQ2uuuWZstdVWceSRR8ZXX30Vl112WfTs2bPSYtIHH3xwTJgwIbbffvs45JBD4uOPP46rr746hg4dGrNnz64ot+Ti44477oi11147evToEeutt16Nt4RFfDMNcPPNN69IuR9//PE4+eSTa3zOxIkT4/PPP6/46/p9990X7733XkR8EwZ169YtIiKOP/74mD9/fgwbNiwWLlwYt99+ezz99NNx8803V3qzX3bZZXHllVfGFltsEZ06dYrbbrut0v5233336Ny5c0RE7LDDDvHWW2/F+PHj49FHH41HH320olyfPn1iu+22i4iIv//973HcccfFmDFjYq211ooFCxbElClT4u67747vfOc7sd9++9V4jNDSNcXx6fDDD4/Zs2fHiBEjom/fvvHhhx/GpEmT4vXXX49LLrmk0qzFU089Ne6888740Y9+FCeeeGJ069Ytrr766li4cGGcd955leq99dZb45133ol58+ZFxDdTuc8555yIiNh///2jf//+Ffu//vrr4+ijj46pU6fG6quvXvHc++67r1J/nH322XH00UfHnnvuGdtvv31MmTIlbrvttjj33HOjR48eNfYL0PzHqNpeQ6222mpxwgknxEUXXRQLFy6MTTfdNH73u9/FlClTYtKkSZVuwaltncccc0zceOONscsuu8Sxxx4b/fv3j3/84x8xefLk2G677SqtJQdU1dTGp169esVuu+1WZftll10WEVHpsU022SS22267uPnmm2P27Nnxgx/8IKZPnx5XXHFFdOzYMU444YRKddTmc+OHH34YG220Ueyzzz4xePDgiIh44IEH4v77748ddtghRo8eXaVtDzzwQMycOdOtbMVWwm+Ga5aW9fWPnTt3rlL29NNPT98+BUu+/vGiiy5Kl1xySerXr19q37592nrrrdOLL75Y5fm33XZbGjhwYGrXrl0aNmxYeuCBB6p8/WNKKT3++ONpk002Se3atav1V0EOHjy44ute33vvvSrHVJ3+/ftX+krHb/97++23K/XRhhtumDp37py6du2att122/S3v/2tSn1LvsKxNnXWVO7bX5P5r3/9Kx1wwAFp4MCBqWPHjqlDhw5p6NCh6fTTT09ffPFFtl+gKWup49PkyZPTqFGjUp8+fVKbNm3SiiuumEaNGpXuvffeasu/+eabaffdd08rrLBC6tixY9pmm23S008/XaXcyJEjlznuPPzww5XKfvTRR2ncuHGpR48eqX379mmzzTZLf/7zn6vd/7XXXpvWWWed1K5duzRo0KB06aWXpsWLF2f7BZo6Y1R+jKrtNVRKKS1atCidd955qX///qldu3Zp6NCh6bbbbqtXna+//noaM2ZM6tevX2rbtm3q379/Ovnkk9PcuXOz/QJNWUsdn6ozcuTINHTo0Crb582bl84666w0ZMiQ1LFjx9StW7e08847pxdeeKFK2dp8bvzss8/Sfvvtl9Zcc83UqVOn1L59+zR06NB03nnnpQULFlTbtr333ju1bds2zZw5s07HRN0UUlpqxT1KZtq0aTFgwIC46KKLsrN+ABqT8QkoZ8YooFwZn2hurIkEAAAAQJYQCQAAAIAsIRIAAAAAWdZEAgAAACDLTCQAAAAAsoRIAAAAAGS1qW3BQqFQzHYATVC53A1rfAKWZnwCylW5jE8RxiigqtwYZSYSAAAAAFlCJAAAAACyhEgAAAAAZAmRAAAAAMgSIgEAAACQJUQCAAAAIKtNqRsAAABAGar5m74j5Qo0gkKhUOPjua8rL0e5Y4oo/nE1x35tCM2hX2rz+qqJmUgAAAAAZAmRAAAAAMgSIgEAAACQJUQCAAAAIEuIBAAAAECWEAkAAACALCESAAAAAFltGm1PqRhVFqHSOioUCvV6fkqlPwYaRzm+VurbJgAAmrHMpWIhV6ABlOLzUrGvkRvimMrxs8W31aZ9uTY0x88qjXFMxT63ZiIBAAAAkCVEAgAAACBLiAQAAABAlhAJAAAAgCwhEgAAAABZQiQAAAAAsoRIAAAAAGQJkQAAAADIalPqBgA0CanY1Rd5B0VQKBSKvo+Uml6/kNcYr50WxfjULBljS8P4VFljvEbq2+eleB3n9lkOx1QObaiv+rYh1wflcIxLK8c2Lc1MJAAAAACyhEgAAAAAZAmRAAAAAMgSIgEAAACQJUQCAAAAIEuIBAAAAECWEAkAAACArDalbgAAAABNT6FQaBb7aGwNcUwppQZoybI1hXNb7D6oTqlfj7XZf7H7xUwkAAAAALKESAAAAABkCZEAAAAAyGq8NZGKcOtgoZ6VluIeyqWV+p7K6tS3X8rxmOqrHF4rAAAAUEpmIgEAAACQJUQCAAAAIEuIBAAAAEBW462JBAAAQLNRDuuG5tZjLUUbm8Mas03h3OY0xXPfFJiJBAAAAECWEAkAAACALCESAAAAAFlCJAAAAACyhEgAAAAAZAmRAAAAAMgSIgEAAACQ1abUDQBoEgrFrr7hd5BSavA6m5tCocgnNop/HopxDF47TUwTHJ+aA++TvMYYYymt5vB7tDq548q1qSm89suhjfU9t+VwDHXVFNu8NDORAAAAAMgSIgEAAACQJUQCAAAAIKvR1kRy33j19Ev1GrpfmsO9pwAAAFBKZiIBAAAAkCVEAgAAACBLiAQAAABAVqOtiQQAAEDL0hLXgG0Kx9wS2phbF7cc+6Ac27Q0M5EAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQFabUjegPgqFQqmbUHb0CRRHSqmo9XvvAsur2OMTLK+m+Nr0+7jxNcU+b4ptXlpzOIZSKHa/NUT9xR57zUQCAAAAIEuIBAAAAECWEAkAAACALCESAAAAAFlCJAAAAACyhEgAAAAAZAmRAAAAAMhqU+oGAAAA0DKllOr1/EKh0EAt+Y/6tqm+anNMpW5jU1CM10ZOsc9LKY5paWYiAQAAAJAlRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABktSl1A+ojpVTqJkShUCh1EyrRJ9Urh34BAICWpr6fDep7Hd9cP5sUu1/Lsd+W1hQ/4+X6tSkck5lIAAAAAGQJkQAAAADIEiIBAAAAkCVEAgAAACBLiAQAAABAlhAJAAAAgCwhEgAAAABZbUrdAABYlkKhUOomQIvnfdh8NcVzm1IqdROoo2Kfs2LUn3tv5PZZ3/dWQxxTqdtQm/03xfdzU2xzQzMTCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgq02pGwAAAED5KRQKTX4fKaWi1r88GuKY63tc9W1DY/RrY7z+6qoc29TYzEQCAAAAIEuIBAAAAECWEAkAAACArEZbE6kc7x0sh/tj9Uv1yq1fyqFPAAAAoJTMRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWY22sDYAAABNRzl8uUyuDcX4Qp5iH3dT6NemoByPoRzb1NDMRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyGpT6gYA0DSllErdBKAReK8Dy1IoFErdhKxitLHY42I59Gs5tKG+yvEYyrFNdWUmEgAAAABZQiQAAAAAsoRIAAAAAGQ12ppIxbhvtBzuJyy3dQL0SfX0CwAAANSPmUgAAAAAZAmRAAAAAMgSIgEAAACQ1WhrIgEAANB8NMSan/Vdu7S5rr2bU+r1VnP7L4c+bIqvjVKf19owEwkAAACALCESAAAAAFlCJAAAAACyhEgAAAAAZAmRAAAAAMgSIgEAAACQJUQCAAAAIKtNqRsAAABA01MoFLJlUkolbUOx918qten7mjSHfqlvHzRF5XDMZiIBAAAAkCVEAgAAACBLiAQAAABAVoteE6kc7idsDveiLq0h+rXc+sVrBQAAgJbOTCQAAAAAsoRIAAAAAGQJkQAAAADIatFrIgE0Z+WwlhdQfN7rtCTWiKQxlPp1Vur9NxX6qXq5fqnvdYOZSAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWW1K3QAAAACoTqFQKOnzq5NSqtfzi9EmqtLPxWEmEgAAAABZQiQAAAAAsoRIAAAAAGQJkQAAAADIatILa9d3QbOGYLGulqEcXmsAAABQSmYiAQAAAJAlRAIAAAAgS4gEAAAAQFaTXhMJAACA5qsUa5PWd93b+ra5Nvu3ZmteOfZRc1hT2UwkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQJYQCQAAAICsNqVuAAARKaVSN6HOCoVC0ffRFPulsTXGeaC8Fft9UozXmPc20FByY1Qxxpum8Lu3vv1Sin6tq3I8D+XQL8VmJhIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQFabUjegPgqFQr2en1JqoJbQ3NX3tdYQvF4BAGhuyvEatxzb1BI5D1WVQ5+YiQQAAABAlhAJAAAAgCwhEgAAAABZQiQAAAAAsoRIAAAAAGQJkQAAAADIEiIBAAAAkNWm1A0AAACgeSoUCi16/yybc1NVQ/RJSqkBWrJsZiIBAAAAkCVEAgAAACBLiAQAAABAlhAJAAAAgCwhEgAAAABZQiQAAAAAsoRIAAAAAGS1KXUDmrqUUqmbQC2Uw3kqFAqlbgJlrBivj3J43Ze7xnhfOg/Q+PzOhfLRFH8P5saQpnBMpR4HG6KPmsN5aGilPq8RZiIBAAAAUAtCJAAAAACyhEgAAAAAZAmRAAAAAMgSIgEAAACQJUQCAAAAIEuIBAAAAECWEAkAAACALCESAAAAAFlCJAAAAACyhEgAAAAAZAmRAAAAAMhqU+oGAAAA0DwVCoWS7j+l1Oj7bIxjLsVxfVtDHGOxjyHXxuXZf7HPbanPa22YiQQAAABAlhAJAAAAgCwhEgAAAABZLXpNpFLfn1uuyqFfyqEN39YU7k0FAACAYjITCQAAAIAsIRIAAAAAWUIkAAAAALJa9JpIACw/a4WVh2Kch0KU17p0lFZTfK83xTZTO0Ufnwx/deK9tnwao9+KvY+Weu7re9zltvbv8jATCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgq02pGwAAAED5KRQK9a4jpVT0fTQ1zeGYHUP1cq/35sBMJAAAAACyhEgAAAAAZAmRAAAAAMhq0msitYT7DWGJQjT9+44BAABousxEAgAAACBLiAQAAABAlhAJAAAAgKwmvSYSAAAAxZFbg7ZQKP6anc1xHdzGOKbcuWmO/VpXy9MHjfGaL3dmIgEAAACQJUQCAAAAIEuIBAAAAECWEAkAAACALCESAAAAAFlCJAAAAACyhEgAAAAAZLUpdQMAmoJCoVDqJtRZU2xzc+Q8UGxeY0BL1hzHwNocU0qp5G2g4TWFfjcTCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQFabxtpRoVBorF1B8+QtBABAGUkplboJZdGGclTfftGvxdEY/Voo8gdHM5EAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWUIkAAAAALLalLoBAAAAlJ9CoVDqJpRFG8qRfilPLeG8mIkEAAAAQJYQCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJBVSCmlUjcCAAAAgPJmJhIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWUKkenjllVdiv/32i759+0b79u1j1VVXjX333TdeeeWVetV73nnnxe9+97uGaWTG448/HmeccUZ8/vnny/X8//3f/41VVlml4ufRo0fHgQceWKXc008/HUcddVRssskm0bZt2ygUCsus86OPPoqDDjooVlpppejYsWNsvPHG8Zvf/KZKubvvvjvGjh0bAwcOjE6dOsU666wTJ510UpVjmTlzZlx00UUxYsSI6N27d3Tv3j0233zzuOOOO6rU+corr8See+5ZUWevXr1ixIgRcd9999W+U6AMGJ9qPz5dd911MXLkyOjTp0+0b98+BgwYEAcddFBMmzat2no/+uijOPzww6Nv377RoUOHWGONNeKQQw6pVOb//u//4ic/+UlsueWW0aFDhygUCsusLyJizpw5MX78+BgwYEC0b98++vbtG2PGjIl58+ZVKvf555/HYYcdFr17947OnTvH97///Xj++edr3SdQDoxPxRmfanv9FBHx/vvvx1577RXdu3ePFVZYIUaPHh1vvfVWvep86KGH4vvf/3706tUrunfvHsOHD49bb721dh0CZcQYVfsx6tsWLlwYQ4YMiUKhEBdffHGVx6dPnx6HHXZYDBgwIDp27BiDBg2KE088MWbOnFmpXF0+NxYKhWr/nX/++ZXKrbHGGsssu9Zaa9WiR6gksVx++9vfpnbt2qWVV145/exnP0vXX399Ou2009Iqq6yS2rVrl+6+++7lrrtz585p3LhxDdfYGlx00UUpItLbb7+9XM/fZ5990m677Vbxc+/evdNVV11Vpdzpp5+e2rZtmzbZZJO09tprp2W99GbNmpXWXHPN1LVr13TaaaeliRMnphEjRqSISJMmTapUtmfPnmn99ddPP//5z9N1112XjjvuuNSuXbs0ePDgNG/evIpy9913X2rbtm0aPXp0uuyyy9LEiRPT97///RQR6Re/+EWlOv/4xz+m7bffPp1xxhnp2muvTZdddlnaeuutU0Ska665Zrn6CBqb8ekbtR2fjjzyyDRu3Lh08cUXpxtuuCGddtppqU+fPqlXr17p/fffr1T23XffTf369Uv9+vVLZ511VrrhhhvS2WefnXbZZZdK5W688cbUqlWrtN5666Vhw4bVeByff/552nDDDVPPnj3Tqaeemm644YZ0/vnnp5122il9+umnFeUWLVqUttxyy9S5c+d0xhlnpIkTJ6YhQ4akrl27pqlTpy5XH0FjMz59o6HHp7pcP82ZMyettdZaaaWVVkoXXHBBmjBhQurXr19abbXV0owZM5arznvvvTcVCoW05ZZbpiuuuKJS2QkTJixXH0EpGKO+Udsx6tsuueSS1Llz5xQR6aKLLqr02Jw5c1L//v1Tr1690i9+8Yt03XXXpWOOOSa1bds2DRs2LC1atKiibG0/N6aUUkSk7bbbLt16662V/r388suVyt1zzz1VypxzzjkpItJRRx1Vl64hpSREWg7/+te/UqdOndLgwYPTxx9/XOmxTz75JA0ePDh17tw5vfnmm8tVf1MaYAYNGpTOP//8lNI3/RIR6fnnn69S7sMPP6wIdo4++uhlDgYXXnhhioj017/+tWLbokWL0qabbppWXnnl9NVXX1Vsf/jhh6s8/+abb04Rka677rqKbW+99VaaNm1apXKLFy9O22yzTWrfvn364osvajzGr7/+Om244YZpnXXWqbEclAPj03/UdnyqzrPPPpsiIv3yl7+stH3HHXdMAwYMqPRBqzozZ85Ms2fPTinlj+PII49M3bt3T2+99VaNdd5xxx0pItJvfvObim0ff/xx6t69e9pnn31qcVRQWsan/2jo8aku108XXHBBioj09NNPV2x77bXXUuvWrdOpp566XHVut912adVVV03z58+v2LZw4cI0aNCgtMEGG9TquKDUjFH/Udcx6qOPPkrdunVLZ511VrUh0qRJk1JEpD/84Q+Vtv/iF7+oUndtPzem9E2IdPTRR9f5+FJK6eyzz04RkR577LHlen5LJkRaDocffniKiPTII49U+/g//vGPFBHp8MMPr9g2bty41L9//yplTz/99EpvjIio8m/JYLOk7GuvvZb23HPP1LVr19SjR4903HHHpS+//LKijrfffjtFRLrxxhur7C8i0umnn16pvqX/1TTYLFq0KH3yySfpk08+qRhQ7rnnnvTJJ5+ka665JrVv3z5Nnz49ffLJJ5UuJL6tpsFgl112Sb17966yfclA+Je//GWZbUsppdmzZ6eISCeeeGKN5VJK6fLLL08RkV566aVs2Z133jn16dMnWw5KzfhUv/FpiRkzZqSISKecckrFttdeey1FRLryyitTSil9+eWXacGCBTXWk1LNF3KfffZZ6tChQxo/fnxKKaWvvvpqmW3bc889U58+fSr9tS6llA477LDUqVOn7DFBqRmfijc+1eX6adNNN02bbrpplbI/+MEP0qBBg5arzs022ywNHTq0StnNNtssbbbZZjUeD5QLY9Tyj1EHHXRQGj58eHrrrbeqDZGuuuqqFBHpmWeeqXb7a6+9Vm27ahsizZs3r1Jf1ca6666bBgwYUKfn8I02QZ3dd999scYaa8TWW29d7eMjRoyINdZYI/74xz/Wue5bb701Dj300Bg+fHgcdthhERExaNCgSmX22muvWGONNeKXv/xlPPnkk3H55ZfHZ599Frfcckud9rXHHnvE1KlTY/LkyXHppZdGr169IiKid+/ey3zOu+++GwMGDKi0bffdd6/085L7Z2+88cbsvbNL++qrr6Jjx45Vtnfq1CkiIp577rnYbrvtlvn8Dz/8MCKi4lhqUlPZuXPnxpdffhmzZs2K3//+9/GnP/0pxo4dW6tjgFIyPi3/+DRz5sxYtGhRvPvuu3HWWWdFRMS2225b8fhDDz0UERF9+vSJbbfdNv72t79F69atY7vttourrroq1lhjjTodY0TEo48+GvPnz48111wzxowZE7/73e9i8eLFscUWW8SvfvWrGDZsWEXZF154ITbeeONo1arycobDhw+Pa6+9NqZOnRrrr79+ndsAjcX4VLzxqbbXT4sXL46XXnopDj744Cplhw8fHn/5y19izpw50bVr1zpdk33ve9+LCy64IH7+85/HuHHjolAoxO233x7PPvts3HnnncvsFygnxqjlG6OefvrpuPnmm+PRRx9d5vpFI0aMiFatWsXxxx8fl1xySay22mrx0ksvxbnnnhu77bZbDB48uE7H+G033XRTXHnllZFSinXXXTdOO+20+PGPf1zjc1544YV47bXX4mc/+9ly77clEyLV0axZs+KDDz6I0aNH11hugw02iN///vcVv4hra7/99osjjjgiBg4cGPvtt1+1ZQYMGBD33ntvREQcffTRscIKK8SVV14ZJ598cmywwQa13tcGG2wQG2+8cUyePDl22223Wn0AWnnllePBBx+MiIgrrrgi3nnnnYqF08aNGxc77rhj7L333hERMXTo0Fq3ZYl11lknHnrooXjnnXeif//+FdunTJkSEd8sBFmTCy64IFq3bh1jxoypsdynn34a119/fWy99daVFo1b4qSTToprrrkmIiJatWoVe+yxR0ycOLGuhwONyvhUv/Gpb9++8dVXX0VERM+ePePyyy+vFFq/8cYbERFx2GGHxaabbhp33HFHvPvuu3HmmWfGqFGj4qWXXqr4cFVbS+o89dRTY9CgQXHLLbfErFmz4swzz4xtttkmXnnllYoxavr06TFixIgqdSx5/IMPPhAiUbaMT8Udn2p7/fTpp5/GV199Ve21z7fHknXWWadO12Q///nP4+23345zzz03zjnnnIj4Jmz67W9/mz3nUA6MUcs3RqWU4thjj42xY8fGFltsscwvERkyZEhce+21cfLJJ8cWW2xRsX3cuHFx/fXX1/rYlrblllvGXnvtFQMGDIgPPvggfvWrX8W+++4bs2bNiiOPPHKZz5s0aVJEROy7777Lve+WTIhUR3PmzImIyA4aSx6fPXt2nQaY2jj66KMr/XzsscfGlVdeGffff3+dBpjl0aFDhxg1alRERIwfPz5++MMfxqhRo+KTTz6J6dOnx/777x8jR45c7voPPfTQuPrqq2OvvfaKSy+9NPr06RN33nln3HPPPRER8eWXXy7zubfffnvccMMNMX78+BpX2V+8eHHsu+++8fnnn8cVV1xRbZkTTjghxowZEx988EHceeedsWjRoliwYMFyHxc0BuNT/canP/3pTzF//vx47bXX4rbbbou5c+dWevyLL76IiG8utP74xz9WzAhabbXVYp999onbb789Dj300Dq1eUmdhUIh/vrXv0aXLl0iImKjjTaqmI205APZl19+Ge3bt6/2uJc8DuXK+FTc8am2109L/q/NWFKXa7L27dvH2muvHWPGjIk99tgjFi1aFNdee23st99+8eCDD8bmm2++XP0GjcUYtXxj1E033RT//Oc/46677sruo2/fvjF8+PD44Q9/GP37948pU6bE5ZdfHr169ar229xq47HHHqv088EHHxybbLJJ/PSnP40DDzyw2tmUixcvjl//+tex0UYbxbrrrrtc+23phEh1tGSwWDLQLEttB6LlsXRAMmjQoGjVqlWNXx/dUGbMmBER3wycL774Yvz0pz+NGTNmxB//+Mdo27ZtrLnmmjFjxozo1KlTnf8iH/FNcn777bfHEUccEd/97ncj4psPbJdddlkceeSRFR+wljZlypQ45JBDYvvtt49zzz23xn0ce+yx8ec//zluueWW2HDDDastM3jw4IpplQcccED84Ac/iF122SWeeuqpGr9mEkrJ+FS/8en73/9+RETsuOOOMXr06FhvvfWiS5cuccwxx0REVFyI7LXXXpVuKdtzzz1j//33j8cff7zOIdKSOnfZZZdK49vmm28eAwYMiMcff7xS2SUzEb5t/vz5leqCcmR8Ku74VNvrpyXjRG3Gkrpckx1zzDHx5JNPxvPPP18xPu61114xdOjQOP744+Opp56qZw9CcRmj6j5GzZ49O0499dT47//+7+jXr1+N9T/22GOx8847x5NPPhnf+c53IiJit912ixVWWCHOPPPMOPjgg2PIkCH1Po527drFMcccE0cccUQ899xzsdVWW1Up849//CPef//9+MlPflLv/bVUrfJF+LZu3brFKqusEi+99FKN5V566aXo27dvrLDCChERywweFi1aVO82LV13MffVu3fv6N27dwwaNCgWL14ce+65Z/Tu3TsOOuigWLBgQay22mrRu3fvuPDCC5d7H0tmAD399NPxxBNPxDvvvBMDBw6MiIi11167SvkXX3wxdt1111hvvfXirrvuijZtlp2NnnnmmXHllVfG+eefH/vvv3+d2vTMM8/E1KlT635A0EiMTw03Pg0aNCg22mijiunOERGrrrpqRHyzJtK3tW7dOnr27BmfffZZndu8rDojIlZaaaVKda6yyioxffr0KuWWbFtSF5Qj41Nxx6eI2l0/9ejRI9q3b1/rsaQ2dS5YsCBuuOGG2GmnnSoF7G3bto0dd9wxnn32WbO5KXvGqLqPURdffHEsWLAgxo4dG9OmTYtp06bFe++9FxERn332WUybNq3ivX/NNddEnz59KgKkJXbddddIKVX6o1l9LQm0Pv3002ofnzRpUrRq1Sr22WefBttnS2Mm0nLYeeed47rrrotHH3202nRzypQpMW3atDj88MMrtq244orx+eefVyn7zjvvVNmWm+nyxhtvVFr47F//+lcsXry44n7XFVdcMSKiyv6WZ19LW3Kv7NVXXx1Tp06NCRMmRMQ3U5633XbbijfjkguM5dWuXbvYdNNNK35esqDtkmmWS7z55puxww47xEorrRT333//MmcqRUT86le/ijPOOCNOOOGEOOWUU+rUniVTtmfNmlWn50FjMz413Pj05ZdfVvpr/SabbBIRVddmW7BgQcyYMaPGBSuXZVl1RnyzLsm3F5ocNmxYTJkyJRYvXlzpg9pTTz0VnTp1qjZkh3JifCre+LRE7vqpVatWsf7668ezzz5b5blPPfVUDBw4sMoMi1ydM2fOjK+//rraD7ILFy6MxYsXN8iHXCg2Y1Tdxqh33303Pvvss2rXcTvvvPPivPPOixdeeCGGDRsWH3300TLHiIiIr7/+uk7trclbb70VEdUvJP7VV1/Fb3/72/je977nj2/1UeJvh2uSpk6dmjp27JiGDBmSZsyYUemxmTNnpiFDhqROnTqlf/3rXxXbJ06cmCIivfjiixXbPvjgg9SlS5cqX1vYp0+fNHr06Cr7XfJ1jbvuumul7UcddVSKiPT//X//X8W2Xr16pd13371SuZNOOqnS1z+m9J+vVXzhhRdqe/gppZRGjBiRjj/++JRSSl988UVq3bp1+tOf/lSr5+a+qnFpU6dOTV27dk0777xzpe3Tp09PAwcOTKuuumqNX1mZUkq//vWvU6tWrdK+++6bFi9evMxyH330UZVtCxYsSBtvvHHq2LFjmjNnTq3bDaVgfKrb+LRw4cL06aefVtn+1FNPpdatW6f999+/Ytv8+fPTSiutlAYOHFjpa2SvueaaFBHpzjvvrHYfS74Oe1nj1IYbbphWWGGF9Mknn1Rse+CBB1JEpAsvvLBi269//esUEek3v/lNxbZPPvkkde/ePY0dO7bauqGcGJ+KNz5VZ1nXT+eff36Vr9p+/fXXU+vWrdMpp5xS5zq//vrr1L1797T22munr776qmL7nDlz0mqrrZYGDx5cY51QLoxRdRujnnvuuXTPPfdU+rfkmujAAw9M99xzT/r8889TSikdc8wxKSLSww8/XKmOE044IUVEevLJJ6vdR02fGz/++OMq22bPnp0GDRqUevXqVWk8WuLuu+9OEZFuuOGGZXUBtWAm0nJYa6214uabb45999031l9//TjkkENiwIABMW3atLjhhhtixowZMXny5Epf27j33nvHKaecErvvvnscd9xxMW/evLjqqqti7bXXjueff75S/Ztsskk89NBDMWHChFh11VVjwIABsdlmm1U8/vbbb8euu+4aO+ywQzzxxBNx2223xY9//ONK6/sceuihcf7558ehhx4a3/nOd+KRRx6p9lasJX8F/9nPfhZ77713tG3bNnbZZZfo3LnzMo9/4cKF8cwzz1Qs/vbUU09VfCX1srzzzjtx6623RkRU/PVryWKx/fv3r3Rr2ZAhQ2LPPfeM1VdfPd5+++246qqrokePHnH11VdXqnOHHXaIt956K8aPHx+PPvpoPProoxWP9enTp+JbS55++uk44IADomfPnrHttttWmf695ZZbVqTqhx9+eMyePTtGjBgRffv2jQ8//DAmTZoUr7/+elxyySU1znSCcmB8qtv49MUXX0S/fv1i7NixMXTo0OjcuXP885//jBtvvDG6desWP//5zyvKtm/fPi666KIYN25cjBgxIvbff/94991343//939j6623jj322KOi7KxZsyoW7l+y6OPEiROje/fu0b1794p1TCIiLr300thuu+1iq622isMPPzxmzZoVEyZMiLXXXrvSN4uMGTMmNt988zjooIPi1VdfjV69esWVV14ZixYtijPPPHOZfQLlwvhUvPEpovbXT0cddVRcd911sdNOO8XJJ58cbdu2jQkTJkSfPn3ipJNOqnOdrVu3jpNPPjlOO+202HzzzeOAAw6IRYsWxQ033BDvvfde3HbbbcvsEygnxqi6jVEbb7xxbLzxxpW2LVm/aejQobHbbrtVbD/mmGPixhtvjF122SWOPfbY6N+/f/zjH/+IyZMnx3bbbVepH2r7ufFXv/pV/O53v4tddtklVl999Zg+fXr8v//3/+Ldd9+NW2+9Ndq1a1elzZMmTYr27dvHj370o2X2A7VQ6hSrKXvppZfSPvvsk1ZZZZXUtm3btPLKK6d99tkn/fOf/6y2/F/+8pe03nrrpXbt2qV11lkn3XbbbRXJ87e9/vrracSIEaljx44pItK4ceNSSv9JqV999dU0ZsyY1LVr17TiiiumY445ptJfxVNKad68eemQQw5J3bp1S127dk177bVX+vjjj6uk1CmldPbZZ6e+ffumVq1a1fjX8iWefPLJFBHp3//+d0oppXPOOScNHTq0xuc8/PDDKSKq/Tdy5MhKZffee+/Ur1+/1K5du7TqqqumI444otoZQsuqb+k6b7zxxhrL3njjjRVlJ0+enEaNGpX69OmT2rRpk1ZcccU0atSodO+999Z4fFBujE+1G5+++uqrdPzxx6cNNtggrbDCCqlt27apf//+6ZBDDlnmviZPnpw23HDD1L59+9SnT590zDHHpNmzZ1cq8/bbby9zzOnfv3+VOh988MG0+eabpw4dOqQePXqk/fffP02fPr1KuU8//TQdcsghqWfPnqlTp05p5MiRlWYTQFNgfCrO+FTb66eUUvr3v/+dxowZk1ZYYYXUpUuXtPPOO6c33nijXnVOmjQpDR8+PHXv3j117NgxbbbZZumuu+6qsU+gHBmjav8Zb2lLrn8uuuiiKo+9/vrracyYMalfv34V49nJJ5+c5s6dW6lcbT83/uUvf0nbbbddWnnllVPbtm1T9+7d0w9+8IP017/+tdq2zZo1K3Xo0CHtsccedTomqiqklFKDJVIU1RlnnBFnnnlmfPLJJ9GrV69SNweggvEJKFfGJ6CcGaNoanw7GwAAAABZQiQAAAAAsoRIAAAAAGRZEwkAAACALDORAAAAAMgSIgEAAACQ1aa2BQuFQjHbATRB5XI3rPEJWJrxCShX5TI+RRijgKpyY5SZSAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQJYQCQAAAICsNqVuAAAAAGWo5m/6jlRonGbUJNeEzCGUpdp0a+5r2OvdhkLNrSj2/stVc+iX3DHkmIkEAAAAQJYQCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJDVptH2lIpQZaHh66yr+jYhpSJ0TH0VyqBjm6FyfK0UnGsAAJYlc6nYGFeSpfi0VOzjaohjqu91fLE/h9amfbk2NMfPKo1xTMU+t2YiAQAAAJAlRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyGpT6gYANAmpyNUXilt/MTRGk1Mqcsc3hkITPLlFpkcamPGpWTLGlkbBmF1JY7xG6tvnpXgV5/qlHI6pvq/kchgf6tuG3Hkoh2NcWoO0qMjjmJlIAAAAAGQJkQAAAADIEiIBAAAAkCVEAgAAACBLiAQAAABAlhAJAAAAgCwhEgAAAABZbUrdAAAAAJqeQqFQ/H0UfQ+NryGOKTVAHTVplHNbz32kVOxeqKox+qXG/deiTLF7xUwkAAAAALKESAAAAABkCZEAAAAAyGq8NZGKcOtgfats/Dsoqyr1PZXVqW+/lN8R1V85vFYAAACglMxEAgAAACBLiAQAAABAlhAJAAAAgKzGWxMJAACAZiOl0q8cmltjtigtzO2znv1SDuvmNoVzm1OKYyh9rxWfmUgAAAAAZAmRAAAAAMgSIgEAAACQJUQCAAAAIEuIBAAAAECWEAkAAACALCESAAAAAFltSt0AgCah0PSqT0Wos7kpFIp8YqP458Frh6Y4PjUH3id5jTHGUlqN8ns0Nf67LXdUuRY1hdd+ObSxvue2HI6hrppei6syEwkAAACALCESAAAAAFlCJAAAAACyGm1NJPeNV0+/VK+h731uivfLAgAAQDkxEwkAAACALCESAAAAAFlCJAAAAACyGm1NJAAAAFqWhl7rtCloCkfcFM5LfduYWxe3HHugQc5LkdcDNhMJAAAAgCwhEgAAAABZQiQAAAAAsoRIAAAAAGQJkQAAAADIEiIBAAAAkCVEAgAAACBLiAQAAABAlhAJAAAAgCwhEgAAAABZQiQAAAAAsoRIAAAAAGS1KXUD6qNQ6gaUIX0CxZFSKmr9hYJ3L7B8ijs6wfIr9u/OYvD7uPE1xT5vei2uqin2ezkodq81xHkp9shrJhIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQFabUjcAAACAlimlVK/nFwqFBmrJf9SvRfVXmyOqb79FEfqt3JTiCIv92imHs2YmEgAAAABZQiQAAAAAsoRIAAAAAGQJkQAAAADIEiIBAAAAkCVEAgAAACBLiAQAAABAVptSN6A+UqkbEBGFUjdgKfqkeinVs2cK5XhUAABQ3gr1vI6u73V8OV7FN8Rntnr3a67+etXeOMrhs29d5fq1KRyTmUgAAAAAZAmRAAAAAMgSIgEAAACQJUQCAAAAIEuIBAAAAECWEAkAAACALCESAAAAAFltSt0AAFiWQqFQ6iZAi+dd2Hw1xTE2pVTqJlBHxT5nxag/997I7bO+762GOKL6vrvr24ba7L8pvpubYpsbmplIAAAAAGQJkQAAAADIEiIBAAAAkCVEAgAAACBLiAQAAABAlhAJAAAAgCwhEgAAAABZbUrdAAAAAMpPoVBo8vtIKRW1/uXREEdc36Oqbxsao1eL/upbjtdGY7wnyp2ZSAAAAABkCZEAAAAAyBIiAQAAAJDVaGsileOdg+Vwd6x+qV653WtaDn0CAAAApWQmEgAAAABZQiQAAAAAsoRIAAAAAGQJkQAAAADIarSFtQEAAGg6Uir918vk2lCML+Qp9nGXvlfLow31VQ6vz6WVX4sanplIAAAAAGQJkQAAAADIEiIBAAAAkCVEAgAAACBLiAQAAABAlhAJAAAAgCwhEgAAAABZbUrdAACaplTqBgCNwnudslIolLoFfEuhCZyPYrQxpeKOjOXQq+XQhvoqx9dn+bWo7sxEAgAAACBLiAQAAABAlhAJAAAAgKxGWxOpGPeNlsM9juW2TkDpe6T8+iSimfRLGbzeAQAAaLnMRAIAAAAgS4gEAAAAQJYQCQAAAICsRlsTCQAAgOajIda9re86t8117d2ceh93kfu9HPqwKb42ynF94aWZiQQAAABAlhAJAAAAgCwhEgAAAABZQiQAAAAAsoRIAAAAAGQJkQAAAADIEiIBAAAAkNWm1A0AAACg6SkUCtkyKaWStqHY+y+V2vR9TZpDr9S3D5qicjhiM5EAAAAAyBIiAQAAAJAlRAIAAAAgq0WviVQO9xOW5b2o9bxvuCHuTS23fvFaAQAAoKUzEwkAAACALCESAAAAAFlCJAAAAACyWvSaSADNWTms5QUUn/c6LYk1ImkMqZ5rxNZ7/yXde9Ohn6qXe/3Wdw1jM5EAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWUIkAAAAALLalLoBAAAAUJ1CoVDS51cnpVSv5zd8i6iOfi4OM5EAAAAAyBIiAQAAAJAlRAIAAAAgS4gEAAAAQFbjLaxdjAXNGrzGurNYV8tQ38XzGkQR3kMAAABQW2YiAQAAAJAlRAIAAAAgS4gEAAAAQFbjrYkEAAAAdVCKtUkL9VyLtL5trs3+y2LN1jJXjj3UHFa5NRMJAAAAgCwhEgAAAABZQiQAAAAAsoRIAAAAAGQJkQAAAADIEiIBAAAAkCVEAgAAACCrTakbAEBESqnUTaizQqFQ9H00xX5pbI1xHihvxX6fFOM15p0NNJTcGFWMMbIp/O6tb7+Uol/rqhzPQul7pfjMRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyGpT6gbUR6Gez08N0gpagkKhvq+2+vN6BQCguUmp/K5yy7FNLZGzUFWt+qTIn13NRAIAAAAgS4gEAAAAQJYQCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyGpT6gYAAADQPBUKhRa9f5bNmamqIfokNUAdNTETCQAAAIAsIRIAAAAAWUIkAAAAALKESAAAAABkCZEAAAAAyBIiAQAAAJAlRAIAAAAgq02pG9DUpVI3gFoph/NUKHUDKGuFQsO/QlIqh1d+eStGvy/NeYDG53culI+m+Hswd33QFI6pMa5xatIQfdQczkNDK/V5jTATCQAAAIBaECIBAAAAkCVEAgAAACBLiAQAAABAlhAJAAAAgCwhEgAAAABZQiQAAAAAsoRIAAAAAGQJkQAAAADIEiIBAAAAkCVEAgAAACBLiAQAAABAVptSNwAAAIDmqVAolHT/KaVG32djHHMpjuvbGuIYi30MuTYuz/6LfW5LfV5rw0wkAAAAALKESAAAAABkCZEAAAAAyGrRayKV9u7c8lXq+5Yjyu/clP+dqQAAAFBcZiIBAAAAkCVEAgAAACBLiAQAAABAVoteEwmA5ZeS1cLKQTHOQ6HYK9OV28J31Kgo7/Uir79odGq+CsU+ucanOnEtsHwao9+KvY+Weu7re9zlsP5wfZmJBAAAAECWEAkAAACALCESAAAAAFlCJAAAAACyhEgAAAAAZAmRAAAAAMgSIgEAAACQ1abUDQAAAKD8FAqFeteRUir6Ppqa5nDMjqF6udd7c2AmEgAAAABZQiQAAAAAsoRIAAAAAGQ16TWRmv/dhvAfhWK84Jv+rcwAAAA0EjORAAAAAMgSIgEAAACQJUQCAAAAIKtJr4kEAABAcaRU86KchULxF9jMtaEpaoxjyp2b5tivdbU8fdAYr/lyZyYSAAAAAFlCJAAAAACyhEgAAAAAZAmRAAAAAMgSIgEAAACQJUQCAAAAIEuIBAAAAEBWm1I3AKApKBQKpW5CnTXFNjdHzgPF5jVGi+LlzlKa4xhYm2NKKZW8DTS8ptDvZiIBAAAAkCVEAgAAACBLiAQAAABAlhAJAAAAgCwhEgAAAABZQiQAAAAAsoRIAAAAAGQJkQAAAADIatNYOyo01o6gufImAgCgjKSUSt2EsmhDOapvv+jX4miMfi3kPjjW83OlmUgAAAAAZAmRAAAAAMgSIgEAAACQJUQCAAAAIEuIBAAAAECWEAkAAACALCESAAAAAFltSt0AAAAAyk+hUCh1E8qiDeVIv5SnlnBezEQCAAAAIEuIBAAAAECWEAkAAACALCESAAAAAFlCJAAAAACyhEgAAAAAZAmRAAAAAMgqpJRSqRsBAAAAQHkzEwkAAACALCESAAAAAFlCJAAAAACyhEgAAAAAZAmRAAAAAMgSIgEAAACQJUQCAAAAIEuIBAAAAECWEAkAAACArP8flzjot/8OEbAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: DataLoader\n",
        "\n",
        "def create_dataloader(data_dir: str,\n",
        "                      batch_size: int = 64,\n",
        "                      num_batches: int = None,\n",
        "                      shuffle: bool = True,\n",
        "                      num_workers: int = 2) -> DataLoader:\n",
        "    \"\"\"\n",
        "    Creates a DataLoader for training.\n",
        "\n",
        "    Args:\n",
        "        data_dir: path to maze dataset\n",
        "        batch_size: samples per training batch\n",
        "        num_batches: how many .npz files to use (None = all)\n",
        "        shuffle: randomize order each epoch\n",
        "        num_workers: parallel data loading processes\n",
        "    \"\"\"\n",
        "    dataset = MazeDataset(data_dir, num_batches=num_batches)\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,  # Faster GPU transfer\n",
        "        drop_last=True     # Avoid weird batch sizes at the end\n",
        "    )\n",
        "\n",
        "    return loader\n",
        "\n",
        "# Test it\n",
        "loader = create_dataloader(DATA_DIR, batch_size=64, num_batches=10)\n",
        "batch_inp, batch_out = next(iter(loader))\n",
        "print(f\"Batch input shape: {batch_inp.shape}\")   # (64, 3, 64, 64)\n",
        "print(f\"Batch output shape: {batch_out.shape}\")  # (64, 3, 64, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "L1Cg4Z9IW9zX",
        "outputId": "fd4cb783-1346-402c-ae9d-6a3e8d5f7b53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'DataLoader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1496143581.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mnum_batches\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                       num_workers: int = 2) -> DataLoader:\n\u001b[0m\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m     \u001b[0mCreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataLoader\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataLoader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TimestepEmbedder(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, frequency_embedding_size=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mlp = nn.Sequential (\n",
        "            nn.Linear(frequency_embedding_size, hidden_size, bias=True),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_size, hidden_size, bias=True)\n",
        "        )\n",
        "\n",
        "        self.frequency_embedding_size = frequency_embedding_size\n",
        "\n",
        "    @staticmethod\n",
        "    def timestep_embedding(t, dim, max_period=10000):\n",
        "\n",
        "        half = dim // 2\n",
        "\n",
        "        freqs = torch.exp(\n",
        "           -math.log(max_period) * torch.arange(half, device=t.device) / half\n",
        "        )\n",
        "        # (bs, 1), (1, 128)\n",
        "        args = t[:, None] * freqs[None, :]\n",
        "\n",
        "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "\n",
        "        return embedding\n",
        "\n",
        "    def forward (self, t):\n",
        "      seq_t = self.timestep_embedding(t, self.frequency_embedding_size)\n",
        "      embed_t = self.mlp(seq_t)\n",
        "\n",
        "      return embed_t"
      ],
      "metadata": {
        "id": "AQuqmmxK3EEB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbed(nn.Module):\n",
        "  def __init__ (self, img_size=64, patch_size=8, in_channels=3, patch_embed_size=384):\n",
        "    super().__init__()\n",
        "    self.image_size = img_size\n",
        "    self.patch_size = patch_size\n",
        "    self.num_patches = (img_size // patch_size) **2\n",
        "    self.proj = nn.Conv2d(in_channels, patch_embed_size, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.proj(x) # B, 384, 8, 8)\n",
        "    x = x.flatten(2) # B, 384, 64\n",
        "    x = x.transpose(1, 2) # B, 64, 384\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "u8jYdbk1JmHG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_1d_sincos_pos_embed(embed_dim, pos):\n",
        "  assert embed_dim % 2 == 0\n",
        "  omega = np.arange(embed_dim // 2, dtype=np.float32)\n",
        "  omega = omega / (embed_dim // 2)\n",
        "  omega = 1.0 / 10000 ** omega\n",
        "  out = np.outer (pos, omega)\n",
        "  embed_sin = np.sin(out)\n",
        "  embed_cos = np.cos(out)\n",
        "  pos_embed = np.concatenate([embed_sin, embed_cos], axis=1)\n",
        "  return pos_embed\n",
        "\n",
        "\n",
        "def get_2d_sincos_pos_embed(embed_dim, grid_size):\n",
        "  grid_w = np.arange(grid_size, dtype=np.float32)\n",
        "  grid_h = np.arange(grid_size, dtype=np.float32)\n",
        "  grid = np.meshgrid(grid_w, grid_h)\n",
        "  flatten_x = grid[0].reshape(-1)\n",
        "  flatten_y = grid[1].reshape(-1)\n",
        "  embed_x = get_1d_sincos_pos_embed(embed_dim // 2, flatten_x)\n",
        "  embed_y = get_1d_sincos_pos_embed(embed_dim // 2, flatten_y)\n",
        "  pos_embed = np.concatenate([embed_x, embed_y], axis=1)\n",
        "  return pos_embed"
      ],
      "metadata": {
        "id": "KXlxcQwD36i5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_test = np.arange(64, dtype=np.float32)\n",
        "emb_1d = get_1d_sincos_pos_embed(192, pos_test)\n",
        "print(f\"Shape 1D: {emb_1d.shape}\")  # (64, 192)\n",
        "\n",
        "emb_2d = get_2d_sincos_pos_embed(384, 8)\n",
        "print(f\"Shape 2D: {emb_2d.shape}\")  # (64, 384)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtkBaOR24TVi",
        "outputId": "82b56a9d-c15c-4047-a110-2ff703093ccf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape 1D: (64, 192)\n",
            "Shape 2D: (64, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DiTBlock (nn.Module):\n",
        "  def __init__(self, hidden_size, num_heads):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.adaLN_modulation = nn.Sequential(\n",
        "        nn.SiLU(),\n",
        "        nn.Linear(hidden_size, 4 * hidden_size)\n",
        "    )\n",
        "\n",
        "    self.norm1 = nn.LayerNorm(hidden_size, elementwise_affine=False)\n",
        "    self.norm2 = nn.LayerNorm(hidden_size, elementwise_affine=False)\n",
        "\n",
        "    self.W_Q_proj = nn.Linear(hidden_size, hidden_size)\n",
        "    self.W_K_proj = nn.Linear(hidden_size, hidden_size)\n",
        "    self.W_V_proj = nn.Linear(hidden_size, hidden_size)\n",
        "    self.W_out_proj = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Linear(hidden_size, 4 * hidden_size),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(4 * hidden_size, hidden_size)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward (self, x, embed_t):\n",
        "    long_time_vector = self.adaLN_modulation(embed_t)\n",
        "    gamma_1, beta_1, gamma_2, beta_2 = torch.chunk(long_time_vector, 4, -1)\n",
        "    normalized_x = (gamma_1.unsqueeze(1) * (self.norm1(x))) + beta_1.unsqueeze(1) # (B, 64, 384)\n",
        "\n",
        "    Q = self.W_Q_proj(normalized_x)\n",
        "    K = self.W_K_proj(normalized_x)\n",
        "    V = self.W_V_proj(normalized_x)\n",
        "\n",
        "    batch_size, seq_length, _ = Q.shape\n",
        "    Q = Q.reshape(batch_size, seq_length, self.num_heads, -1).transpose(1, 2)\n",
        "    K = K.reshape(batch_size, seq_length, self.num_heads, -1).transpose(1, 2)\n",
        "    V = V.reshape(batch_size, seq_length, self.num_heads, -1).transpose(1, 2)\n",
        "\n",
        "    dim_per_head = self.hidden_size / self.num_heads\n",
        "    attention_scores_matrix = (Q @ K.transpose(2, 3)) / math.sqrt(dim_per_head) # (bs, heads, seq, seq)\n",
        "    attention_scores_matrix = F.softmax(attention_scores_matrix, dim=-1)\n",
        "    attention_output = attention_scores_matrix @ V # (seq, seq) @ (seq, dim_per_head)-> (seq, dim_per_head)\n",
        "\n",
        "    attention_output = attention_output.transpose(1, 2).reshape(batch_size, seq_length, -1)\n",
        "    proj_attention_output = self.W_out_proj(attention_output) + x\n",
        "\n",
        "    normalized_x_second = (gamma_2.unsqueeze(1) * (self.norm2(proj_attention_output))) + beta_2.unsqueeze(1)\n",
        "    processed_normalized_x_second = self.mlp(normalized_x_second)\n",
        "    output = processed_normalized_x_second + proj_attention_output\n",
        "\n",
        "    return output\n",
        "\n"
      ],
      "metadata": {
        "id": "PI3-hodiAUXg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block = DiTBlock(hidden_size=384, num_heads=6)\n",
        "x_dummy = torch.randn(2, 64, 384)      # (batch, seq, hidden)\n",
        "t_dummy = torch.randn(2, 384)          # (batch, hidden)\n",
        "out = block(x_dummy, t_dummy)\n",
        "print(out.shape)  # (2, 64, 384)"
      ],
      "metadata": {
        "id": "QxnRKMPC7xC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d0a142-f1b9-4d76-8d5f-0a37c5b3d903"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 64, 384])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FinalLayer(nn.Module):\n",
        "  def __init__ (self, hidden_size, pixels_per_seq, grid_size, patch_size):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.pixels_per_seq = pixels_per_seq\n",
        "    self.grid_size = grid_size\n",
        "    self.patch_size = patch_size\n",
        "\n",
        "    self.adaLN_modulation = nn.Sequential (\n",
        "        nn.SiLU(),\n",
        "        nn.Linear(hidden_size, 2 * hidden_size)\n",
        "    )\n",
        "    self.layer_norm = nn.LayerNorm(hidden_size, elementwise_affine=False)\n",
        "\n",
        "    self.mlp = nn.Linear(hidden_size, pixels_per_seq)\n",
        "\n",
        "  def forward (self, x, embed_t):\n",
        "\n",
        "    long_time_vector = self.adaLN_modulation(embed_t) # bs, 2 * hidden_size\n",
        "    gama, beta = torch.chunk(long_time_vector, 2, -1)\n",
        "    normalized_x = (gama.unsqueeze(1) * self.layer_norm(x)) + beta.unsqueeze(1) # bs, seq, hidden_size\n",
        "\n",
        "    projected_normalized_x = self.mlp(normalized_x) # bs, seq, pixels_per_seq\n",
        "\n",
        "    bs, seq, _ = projected_normalized_x.shape\n",
        "    intermediary_output_1 = projected_normalized_x.reshape(bs, self.grid_size, self.grid_size, self.pixels_per_seq)\n",
        "    intermediary_output_2 = intermediary_output_1.reshape(bs, self.grid_size, self.grid_size, 3, self.patch_size, self.patch_size)\n",
        "    intermediary_output_3 = intermediary_output_2.permute(0, 3, 1, 2, 4, 5) # bs, channels, y_grid, x_grid, y_patch, x_patch\n",
        "    intermediary_output_4 = intermediary_output_3.permute(0, 1, 2, 4, 3, 5) # bs, channels, y_grid, y_patch, x_grid, x_patch\n",
        "    output = intermediary_output_4.reshape(bs, 3, self.grid_size * self.patch_size, self.patch_size * self.grid_size)\n",
        "    return output"
      ],
      "metadata": {
        "id": "ETmKSTwi7Gvm"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = FinalLayer(hidden_size=384, pixels_per_seq=192, grid_size=8, patch_size=8)\n",
        "x_dummy = torch.randn(2, 64, 384)   # (batch, seq, hidden)\n",
        "t_dummy = torch.randn(2, 384)       # (batch, hidden)\n",
        "out = final(x_dummy, t_dummy)\n",
        "print(out.shape)  # (2, 3, 64, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuNcsZZXZIWe",
        "outputId": "dd91a391-6988-47f2-e316-19ea74486ff5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TACITModel(nn.Module):\n",
        "  def __init__(self,\n",
        "               hidden_size=384,\n",
        "               frequency_embedding_size=256,\n",
        "               patch_size=8,\n",
        "               in_channels=3,\n",
        "               num_heads=6,\n",
        "               grid_size=8,\n",
        "               num_blocks=8):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "    self.frequency_embedding_size = frequency_embedding_size\n",
        "    self.patch_size = patch_size\n",
        "    self.in_channels = in_channels\n",
        "    self.num_heads = num_heads\n",
        "    self.grid_size = grid_size\n",
        "    self.num_blocks = num_blocks\n",
        "    self.timestep_embedding =  TimestepEmbedder(self.hidden_size, self.frequency_embedding_size)\n",
        "    self.patch_embedding = PatchEmbed(self.patch_size * self.grid_size, self.patch_size, self.in_channels, self.hidden_size)\n",
        "    pos_embedding = torch.from_numpy(get_2d_sincos_pos_embed(self.hidden_size, self.grid_size)).float()\n",
        "    self.register_buffer('pos_embedding', pos_embedding)\n",
        "    self.dit_container = nn.ModuleList([DiTBlock(self.hidden_size, self.num_heads) for _ in range(self.num_blocks)])\n",
        "    self.final_layer = FinalLayer(self.hidden_size, self.patch_size**2 * self.in_channels, self.grid_size, self.patch_size)\n",
        "\n",
        "  def forward (self, x, t):\n",
        "    x = self.patch_embedding(x) # (bs, 3, 64, 64) -> (bs, 64, 384)\n",
        "\n",
        "    pos_embed = self.pos_embedding.unsqueeze(0) # (1, 64, 384)\n",
        "\n",
        "    x += pos_embed\n",
        "\n",
        "    t_embed = self.timestep_embedding(t) # (bs, 384)\n",
        "\n",
        "    for transformer_block in self.dit_container:\n",
        "      x = transformer_block(x, t_embed) # (bs, 384)\n",
        "\n",
        "    x = self.final_layer(x, t_embed)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "xPv7VbViZfhX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TACITModel()\n",
        "x_dummy = torch.randn(2, 3, 64, 64)\n",
        "t_dummy = torch.randn(2)\n",
        "out = model(x_dummy, t_dummy)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDxhSnQrBsa2",
        "outputId": "874cfa66-40c4-4f83-a6c3-2b3bdc910d8d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer():\n",
        "  def __init__(self, model=None, optim=None):\n",
        "    self.model = model if model is not None else TACITModel().to(device)\n",
        "    self.optim = optim if optim is not None else torch.optim.Adam(self.model.parameters(), lr=1e-4)\n",
        "\n",
        "  def compute_loss(self, x0, x1):\n",
        "    t = torch.rand(x0.shape[0], device=device)\n",
        "    t_expanded = t.reshape(-1, 1, 1, 1)\n",
        "    xt = (1 - t_expanded) * x0 + t_expanded * x1\n",
        "    v_pred = self.model(xt, t)\n",
        "    loss = (v_pred - (x1 - x0))**2\n",
        "    loss = loss.mean()\n",
        "    return loss\n",
        "\n",
        "  def train_step(self, x0, x1):\n",
        "    x0 = x0.to(device)\n",
        "    x1 = x1.to(device)\n",
        "    loss = self.compute_loss(x0, x1)\n",
        "    loss.backward()\n",
        "    self.optim.step()\n",
        "    self.optim.zero_grad()\n",
        "    return loss.item()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "YAnmFIB3BhdR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_euler_method(model, x0, num_steps=10):\n",
        "  step_delta_t = 1 / num_steps\n",
        "  x = x0\n",
        "  t = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "      for step in range(num_steps):\n",
        "        effective_t = torch.ones(x0.shape[0], device=x0.device)\n",
        "        effective_t = effective_t * t\n",
        "        v_pred = model(x, effective_t)\n",
        "        x = x + (v_pred * step_delta_t)\n",
        "        t += step_delta_t\n",
        "\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "aHaeHBHbOebs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_checkpoint(trainer, checkpoint_path):\n",
        "    from safetensors.torch import load_file\n",
        "\n",
        "    state_dict = load_file(checkpoint_path)\n",
        "    trainer.model.load_state_dict(state_dict)\n",
        "    print(f\"Loaded checkpoint: {checkpoint_path}\")\n",
        "\n",
        "def train(trainer, dataloader, num_epochs, log_every=500, checkpoint_every=5):\n",
        "    all_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "        epoch_start = time.time()\n",
        "        progress_bar = tqdm(enumerate(dataloader), total=len(dataloader),\n",
        "                           desc=f'Epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "        for idx_batch, (x0, x1) in progress_bar:\n",
        "            loss = trainer.train_step(x0, x1)\n",
        "            epoch_losses.append(loss)\n",
        "\n",
        "            progress_bar.set_postfix({'loss': f'{loss:.4f}'})\n",
        "\n",
        "            if idx_batch % log_every == 0 and idx_batch > 0:\n",
        "                avg_recent = sum(epoch_losses[-log_every:]) / log_every\n",
        "                print(f'\\n  Batch {idx_batch}: avg loss = {avg_recent:.4f}')\n",
        "\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        epoch_avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
        "        all_losses.extend(epoch_losses)\n",
        "\n",
        "        print(f'\\nEpoch {epoch+1} complete: avg loss = {epoch_avg_loss:.4f}, time = {epoch_time:.1f}s')\n",
        "\n",
        "        if (epoch + 1) % checkpoint_every == 0:\n",
        "            checkpoint_path = CHECKPOINT_DIR / f'tacit_epoch_{epoch+1}.safetensors'\n",
        "            save_file(trainer.model.state_dict(), str(checkpoint_path))\n",
        "            print(f'  Checkpoint saved: {checkpoint_path.name}')\n",
        "\n",
        "    return all_losses\n",
        "\n",
        "def visualize_predictions(model, dataset, num_samples=4, num_steps=10):\n",
        "    model.eval()\n",
        "\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(9, 3*num_samples))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        idx = np.random.randint(len(dataset))\n",
        "        x0, x1 = dataset[idx]\n",
        "\n",
        "\n",
        "        x0_batch = x0.unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "        x1_pred = sample_euler_method(model, x0_batch, num_steps)\n",
        "\n",
        "\n",
        "        x0_vis = x0.permute(1, 2, 0).numpy()\n",
        "        x1_vis = x1.permute(1, 2, 0).numpy()\n",
        "        x1_pred_vis = x1_pred[0].cpu().permute(1, 2, 0).numpy()\n",
        "        x1_pred_vis = np.clip(x1_pred_vis, 0, 1)\n",
        "\n",
        "        axes[i, 0].imshow(x0_vis)\n",
        "        axes[i, 0].set_title('Problem')\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        axes[i, 1].imshow(x1_vis)\n",
        "        axes[i, 1].set_title('Real Solution')\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        axes[i, 2].imshow(x1_pred_vis)\n",
        "        axes[i, 2].set_title('Prediction')\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "Fxx-TT4OdoeP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}